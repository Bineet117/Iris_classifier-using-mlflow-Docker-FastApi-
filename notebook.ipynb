{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"IRIS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    0\n",
       "sepal_width     0\n",
       "petal_length    0\n",
       "petal_width     0\n",
       "species         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "# df['species'] = label_encoder.fit_transform(df['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width         species\n",
       "0             5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1             4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2             4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3             4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4             5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145           6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146           6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147           6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148           6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149           5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "y = df['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the entire feature set\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (105, 4)\n",
      "X_test shape: (45, 4)\n",
      "y_train shape: (105,)\n",
      "y_test shape: (45,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Check the shapes of the resulting splits\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=3, random_state=42) Accuracy: 1.00\n",
      "DecisionTreeClassifier(max_depth=3, random_state=42) Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        19\n",
      "Iris-versicolor       1.00      1.00      1.00        13\n",
      " Iris-virginica       1.00      1.00      1.00        13\n",
      "\n",
      "       accuracy                           1.00        45\n",
      "      macro avg       1.00      1.00      1.00        45\n",
      "   weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "# Initialize the classifiers\n",
    "decision_tree = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "\n",
    "\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"{decision_tree} Accuracy: {accuracy:.2f}\")\n",
    "print(f\"{decision_tree} Classification Report:\\n{classification_report(y_test, y_pred)}\\n\")\n",
    "\n",
    "\n",
    "# Assume y_pred is the predicted values and y_test is the true values\n",
    "decision_tree_accuracy = accuracy_score(y_test, y_pred)\n",
    "decision_tree_precision = precision_score(y_test, y_pred, average='weighted')\n",
    "decision_tree_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "decision_tree_f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Logging each metric separately\n",
    "# print(f\"{decision_tree} Accuracy: {accuracy:.2f}\")\n",
    "# print(f\"{decision_tree} Precision: {precision:.2f}\")\n",
    "# print(f\"{decision_tree} Recall: {recall:.2f}\")\n",
    "# print(f\"{decision_tree} F1 Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=3, random_state=42) Accuracy: 1.00\n",
      "RandomForestClassifier(max_depth=3, random_state=42) Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        19\n",
      "Iris-versicolor       1.00      1.00      1.00        13\n",
      " Iris-virginica       1.00      1.00      1.00        13\n",
      "\n",
      "       accuracy                           1.00        45\n",
      "      macro avg       1.00      1.00      1.00        45\n",
      "   weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
    "\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"{random_forest} Accuracy: {accuracy:.2f}\")\n",
    "print(f\"{random_forest} Classification Report:\\n{classification_report(y_test, y_pred)}\\n\")\n",
    "\n",
    "\n",
    "# Assume y_pred is the predicted values and y_test is the true values\n",
    "random_forest_accuracy = accuracy_score(y_test, y_pred)\n",
    "random_forest_precision = precision_score(y_test, y_pred, average='weighted')\n",
    "random_forest_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "random_forest_f1 = f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier() Accuracy: 1.00\n",
      "KNeighborsClassifier() Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        19\n",
      "Iris-versicolor       1.00      1.00      1.00        13\n",
      " Iris-virginica       1.00      1.00      1.00        13\n",
      "\n",
      "       accuracy                           1.00        45\n",
      "      macro avg       1.00      1.00      1.00        45\n",
      "   weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors Classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"{knn} Accuracy: {accuracy:.2f}\")\n",
    "print(f\"{knn} Classification Report:\\n{classification_report(y_test, y_pred)}\\n\")\n",
    "\n",
    "\n",
    "# Assume y_pred is the predicted values and y_test is the true values\n",
    "knn_accuracy = accuracy_score(y_test, y_pred)\n",
    "knn_precision = precision_score(y_test, y_pred, average='weighted')\n",
    "knn_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "knn_f1 = f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1, kernel='linear', random_state=42) Accuracy: 1.00\n",
      "SVC(C=1, kernel='linear', random_state=42) Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        19\n",
      "Iris-versicolor       1.00      1.00      1.00        13\n",
      " Iris-virginica       1.00      1.00      1.00        13\n",
      "\n",
      "       accuracy                           1.00        45\n",
      "      macro avg       1.00      1.00      1.00        45\n",
      "   weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Classifier\n",
    "svm = SVC(kernel='linear', C=1, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"{svm} Accuracy: {accuracy:.2f}\")\n",
    "print(f\"{svm} Classification Report:\\n{classification_report(y_test, y_pred)}\\n\")\n",
    "\n",
    "\n",
    "# Assume y_pred is the predicted values and y_test is the true values\n",
    "svm_accuracy = accuracy_score(y_test, y_pred)\n",
    "svm_precision = precision_score(y_test, y_pred, average='weighted')\n",
    "svm_recall = recall_score(y_test, y_pred, average='weighted')\n",
    "svm_f1 = f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[0;32m      2\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m XGBClassifier(max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m      6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m svm\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\91620\\Desktop\\CA2\\venv\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\91620\\Desktop\\CA2\\venv\\Lib\\site-packages\\xgboost\\sklearn.py:1491\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1486\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1488\u001b[0m     classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1489\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[0;32m   1490\u001b[0m ):\n\u001b[1;32m-> 1491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1492\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1493\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1494\u001b[0m     )\n\u001b[0;32m   1496\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb_model = XGBClassifier(max_depth=3, learning_rate=0.1, n_estimators=100, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"{xgb_model} Accuracy: {accuracy:.2f}\")\n",
    "print(f\"{xgb_model} Classification Report:\\n{classification_report(y_test, y_pred)}\\n\")\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_model_metrics(model, X_train, X_test, y_train, y_test,model_name, experiment_name):\n",
    "    \"\"\"\n",
    "    Trains the given model, logs its metrics, and logs the model itself in MLflow.\n",
    "    \n",
    "    Parameters:\n",
    "    - model: The classifier to be trained and logged.\n",
    "    - X_train: The training features.\n",
    "    - X_test: The test features.\n",
    "    - y_train: The training labels.\n",
    "    - y_test: The test labels.\n",
    "    - model_name: A string to identify the model (used for logging).\n",
    "    \"\"\"\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    with mlflow.start_run():\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        # # Print metrics\n",
    "        # print(f\"{model_name} Accuracy: {accuracy:.2f}\")\n",
    "        # print(f\"{model_name} Precision: {precision:.2f}\")\n",
    "        # print(f\"{model_name} Recall: {recall:.2f}\")\n",
    "        # print(f\"{model_name} F1 Score: {f1:.2f}\")\n",
    "        # print(f\"Classification Report for {model_name}:\\n{classification_report(y_test, y_pred)}\\n\")\n",
    "        \n",
    "        # Log metrics in MLflow\n",
    "        mlflow.log_metric(f\"{model_name}_accuracy\", accuracy)\n",
    "        mlflow.log_metric(f\"{model_name}_precision\", precision)\n",
    "        mlflow.log_metric(f\"{model_name}_recall\", recall)\n",
    "        mlflow.log_metric(f\"{model_name}_f1_score\", f1)\n",
    "        \n",
    "        # Log the model\n",
    "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
    "\n",
    "# Example usage for 5 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/13 13:42:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "log_model_metrics(decision_tree, X_train, X_test, y_train, y_test,'Logistic Regression','decision_tree_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/13 13:42:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "log_model_metrics(random_forest, X_train, X_test, y_train, y_test,'random forest','random_forest_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/13 13:42:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "log_model_metrics(knn, X_train, X_test, y_train, y_test,'KNN','KNN_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/13 13:42:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "log_model_metrics(svm, X_train, X_test, y_train, y_test,'SVM','SVM_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/13 12:56:33 INFO mlflow.tracking.fluent: Experiment with name 'xgb_model_classifier' does not exist. Creating a new experiment.\n",
      "2024/11/13 12:56:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "log_model_metrics(xgb_model, X_train, X_test, y_train, y_test,'xgb_model','xgb_model_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow models serve --env-manager local -m \"models:/model/2\" -p 5555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "lst = X_test.values.tolist()\n",
    "inference_request = {\n",
    "        \"dataframe_records\": lst\n",
    "}\n",
    "endpoint = \"http://localhost:5555/invocations\"\n",
    "response = requests.post(endpoint, json=inference_request)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': ['Iris-versicolor',\n",
       "  'Iris-setosa',\n",
       "  'Iris-virginica',\n",
       "  'Iris-versicolor',\n",
       "  'Iris-versicolor',\n",
       "  'Iris-setosa',\n",
       "  'Iris-versicolor',\n",
       "  'Iris-virginica',\n",
       "  'Iris-versicolor',\n",
       "  'Iris-versicolor',\n",
       "  'Iris-virginica',\n",
       "  'Iris-setosa',\n",
       "  'Iris-setosa',\n",
       "  'Iris-setosa',\n",
       "  'Iris-setosa',\n",
       "  'Iris-versicolor',\n",
       "  'Iris-virginica',\n",
       "  'Iris-versicolor',\n",
       "  'Iris-versicolor',\n",
       "  'Iris-virginica',\n",
       "  'Iris-setosa',\n",
       "  'Iris-virginica',\n",
       "  'Iris-setosa',\n",
       "  'Iris-virginica',\n",
       "  'Iris-virginica',\n",
       "  'Iris-virginica',\n",
       "  'Iris-virginica',\n",
       "  'Iris-virginica',\n",
       "  'Iris-setosa',\n",
       "  'Iris-setosa',\n",
       "  'Iris-setosa',\n",
       "  'Iris-setosa',\n",
       "  'Iris-versicolor',\n",
       "  'Iris-setosa',\n",
       "  'Iris-setosa',\n",
       "  'Iris-virginica',\n",
       "  'Iris-versicolor',\n",
       "  'Iris-setosa',\n",
       "  'Iris-setosa',\n",
       "  'Iris-setosa',\n",
       "  'Iris-virginica',\n",
       "  'Iris-versicolor',\n",
       "  'Iris-versicolor',\n",
       "  'Iris-setosa',\n",
       "  'Iris-setosa']}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"predictions\": [\"Iris-versicolor\", \"Iris-setosa\", \"Iris-virginica\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-virginica\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-versicolor\", \"Iris-virginica\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-virginica\", \"Iris-setosa\", \"Iris-virginica\", \"Iris-setosa\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-virginica\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-versicolor\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-virginica\", \"Iris-versicolor\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-setosa\", \"Iris-virginica\", \"Iris-versicolor\", \"Iris-versicolor\", \"Iris-setosa\", \"Iris-setosa\"]}'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(\"X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow models serve --env-manager local -m \"models:/model/2\" -p 5555"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
